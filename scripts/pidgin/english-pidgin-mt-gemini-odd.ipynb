{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"e3d78fe1-1b17-4ce0-bc4a-37fb6a1ae2b0","_uuid":"31747938-9a7e-4c20-9f53-a78654a6a71c","collapsed":false,"execution":{"iopub.execute_input":"2025-08-13T15:43:47.752337Z","iopub.status.busy":"2025-08-13T15:43:47.751923Z","iopub.status.idle":"2025-08-13T15:43:47.757588Z","shell.execute_reply":"2025-08-13T15:43:47.756714Z","shell.execute_reply.started":"2025-08-13T15:43:47.752307Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["API_1 = \"***************************************\"\n","API_2 = \"***************************************\"\n","API_3 = \"***************************************\"\n","API_4 = \"***************************************\""]},{"cell_type":"code","execution_count":16,"metadata":{"_cell_guid":"e07d6c17-bdb9-45af-bad3-243196fa5b2f","_uuid":"ca02c0f8-48d6-43a6-86ae-97e4ac123d00","collapsed":false,"execution":{"iopub.execute_input":"2025-08-13T15:43:47.759339Z","iopub.status.busy":"2025-08-13T15:43:47.759021Z","iopub.status.idle":"2025-08-13T15:43:47.778815Z","shell.execute_reply":"2025-08-13T15:43:47.777614Z","shell.execute_reply.started":"2025-08-13T15:43:47.759312Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import time\n","from pathlib import Path\n","from typing import List, Dict\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import google.generativeai as genai"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"72729852-c823-45db-8e4d-bc92cda6b5e1","_uuid":"27256fd3-d16e-433a-964b-6b8ef175f023","collapsed":false,"execution":{"iopub.execute_input":"2025-08-13T15:43:47.780152Z","iopub.status.busy":"2025-08-13T15:43:47.779884Z","iopub.status.idle":"2025-08-13T15:43:47.799077Z","shell.execute_reply":"2025-08-13T15:43:47.798185Z","shell.execute_reply.started":"2025-08-13T15:43:47.780131Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["INPUT_DIR = Path(\"/kaggle/input/new-snli/new-snli/\")\n","OUTPUT_DIR = Path(\"./outputs\")\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","MODEL_NAME = os.environ.get(\"GEMINI_MODEL_NAME\", \"models/gemini-2.5-flash-lite\")\n","BATCH_SIZE = 15\n","MAX_RETRIES = 6\n","BASE_BACKOFF = 8  # seconds\n","\n","# You already defined API_1..API_4 earlier in your notebook.\n","# We'll use them directly. If you prefer env vars, say the word and I’ll swap it.\n","\n","# Define exactly which CSV and which column to read for each output file.\n","FILE_SPECS: Dict[str, Dict[str, str]] = {\n","    # file_base -> {\"csv_path\": \"relative/path.csv\", \"column\": \"sentence1|sentence2\", \"api_key_var\": \"API_1|API_2|...\"}\n","    \"dev_df1\":  {\"csv_path\": \"dev/sentence1_translations.csv\", \"column\": \"sentence1\", \"api_key_var\": \"API_1\"},\n","    \"dev_df2\":  {\"csv_path\": \"dev/sentence2_translations.csv\", \"column\": \"sentence2\", \"api_key_var\": \"API_2\"},\n","    \"test_df1\": {\"csv_path\": \"test/sentence1_translations.csv\", \"column\": \"sentence1\", \"api_key_var\": \"API_3\"},\n","    \"test_df2\": {\"csv_path\": \"test/sentence2_translations.csv\", \"column\": \"sentence2\", \"api_key_var\": \"API_4\"},\n","}"]},{"cell_type":"code","execution_count":18,"metadata":{"_cell_guid":"197a71d5-7edd-478f-9134-da249d06c372","_uuid":"31a1feb3-f339-4763-8149-a3aa9815f4c3","collapsed":false,"execution":{"iopub.execute_input":"2025-08-13T15:43:47.800949Z","iopub.status.busy":"2025-08-13T15:43:47.800655Z","iopub.status.idle":"2025-08-13T15:43:47.823028Z","shell.execute_reply":"2025-08-13T15:43:47.822013Z","shell.execute_reply.started":"2025-08-13T15:43:47.800930Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def _get_api_key(var_name: str) -> str:\n","    \"\"\"Fetch API key from a variable you defined (API_1..API_4).\"\"\"\n","    # Look in globals (this notebook) first; fallback to env var.\n","    if var_name in globals():\n","        return globals()[var_name]\n","    return os.environ.get(var_name, \"\")\n","\n","def make_prompt(batch: List[str]) -> str:\n","    numbered = \"\\n\".join(f\"{i+1}. {s}\" for i, s in enumerate(batch))\n","    return (\n","        f\"Translate the following {len(batch)} English sentences into Nigerian Pidgin.\\n\"\n","        f\"Return ONLY the translations, one per line, numbered 1..{len(batch)}.\\n\\n\"\n","        f\"{numbered}\"\n","    )\n","\n","_leading_num_re = re.compile(r\"^\\s*(?:\\d+[\\.\\)\\-:]?\\s*|\\-\\s*|\\*\\s*)\")\n","\n","def parse_translations(text: str, expected_n: int) -> List[str]:\n","    if not text:\n","        return [\"[TRANSLATION FAILED]\"] * expected_n\n","    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n","    cleaned = [_leading_num_re.sub(\"\", ln).strip() for ln in lines]\n","    cleaned = [ln for ln in cleaned if ln]\n","    if len(cleaned) >= expected_n:\n","        return cleaned[:expected_n]\n","    if 0 < len(cleaned) < expected_n:\n","        return cleaned + [\"[MISSING LINE]\"] * (expected_n - len(cleaned))\n","    return [\"[TRANSLATION FAILED]\"] * expected_n\n","\n","def translate_batch(model, batch: List[str]) -> List[str]:\n","    prompt = make_prompt(batch)\n","    backoff = BASE_BACKOFF\n","    for attempt in range(1, MAX_RETRIES + 1):\n","        try:\n","            resp = model.generate_content(prompt)\n","            text = getattr(resp, \"text\", \"\") or \"\"\n","            return parse_translations(text, expected_n=len(batch))\n","        except Exception as e:\n","            msg = str(e)\n","            if any(tok in msg for tok in (\"429\", \"rate\", \"quota\", \"Resource has been exhausted\")):\n","                time.sleep(backoff); backoff *= 2\n","            else:\n","                time.sleep(5)\n","    return [\"[TRANSLATION FAILED]\"] * len(batch)\n","\n","def pick_english_series(df: pd.DataFrame, preferred: str) -> pd.Series:\n","    \"\"\"\n","    Try to use the preferred column ('sentence1' or 'sentence2').\n","    If it's missing, try a few fallbacks commonly seen in SNLI-style exports.\n","    \"\"\"\n","    candidates = [preferred, preferred.lower(), \"text\", \"english\", \"sentence\"]\n","    for c in candidates:\n","        if c in df.columns:\n","            s = df[c].astype(str)\n","            return s\n","    # If nothing matches, just take the first column as a last resort\n","    s = df.iloc[:, 0].astype(str)\n","    return s"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"755ee446-ddd0-497b-abfb-7ff5f8d70978","_uuid":"caa82ad9-6076-4d05-9bf1-6c854b18ca86","collapsed":false,"execution":{"iopub.execute_input":"2025-08-13T15:43:47.824315Z","iopub.status.busy":"2025-08-13T15:43:47.824077Z","iopub.status.idle":"2025-08-13T16:24:45.175829Z","shell.execute_reply":"2025-08-13T16:24:45.174972Z","shell.execute_reply.started":"2025-08-13T15:43:47.824296Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Translating dev_df1: 100%|██████████| 56/56 [03:21<00:00,  3.61s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["✅ Wrote /kaggle/working/outputs/dev_df1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Translating dev_df2: 100%|██████████| 166/166 [10:12<00:00,  3.69s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["✅ Wrote /kaggle/working/outputs/dev_df2.csv\n"]},{"name":"stderr","output_type":"stream","text":["Translating test_df1: 100%|██████████| 112/112 [07:11<00:00,  3.85s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["✅ Wrote /kaggle/working/outputs/test_df1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Translating test_df2: 100%|██████████| 334/334 [20:11<00:00,  3.63s/batch] "]},{"name":"stdout","output_type":"stream","text":["✅ Wrote /kaggle/working/outputs/test_df2.csv\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def process_one(file_base: str, spec: Dict[str, str]):\n","    csv_path = INPUT_DIR / spec[\"csv_path\"]\n","    column = spec[\"column\"]\n","    api_key = _get_api_key(spec[\"api_key_var\"])\n","\n","    if not csv_path.exists():\n","        print(f\"❌ Missing CSV: {csv_path}\")\n","        return\n","    if not api_key:\n","        print(f\"❌ Missing API key for {file_base} ({spec['api_key_var']}).\")\n","        return\n","\n","    # Configure Gemini\n","    genai.configure(api_key=api_key)\n","    model = genai.GenerativeModel(MODEL_NAME)\n","\n","    # Load CSV and pick English column\n","    df_in = pd.read_csv(csv_path)\n","    english_series = pick_english_series(df_in, preferred=column)\n","    english_lines = english_series.fillna(\"\").tolist()\n","\n","    if not any(ln.strip() for ln in english_lines):\n","        print(f\"⚠️ No non-empty lines found in {csv_path}. Skipping.\")\n","        return\n","\n","    # Batching\n","    batches = [english_lines[i:i+BATCH_SIZE] for i in range(0, len(english_lines), BATCH_SIZE)]\n","    pidgin_all: List[str] = []\n","\n","    for batch in tqdm(batches, desc=f\"Translating {file_base}\", unit=\"batch\"):\n","        pidgin_all.extend(translate_batch(model, batch))\n","\n","    # Build required schema\n","    out_df = pd.DataFrame({\n","        \"no\": range(1, len(english_lines) + 1),\n","        \"english\": english_lines,\n","        \"pidgin\": pidgin_all\n","    })\n","\n","    out_path = OUTPUT_DIR / f\"{file_base}.csv\"  # exact names requested\n","    out_df.to_csv(out_path, index=False)\n","    print(f\"✅ Wrote {out_path.resolve()}\")\n","\n","def main():\n","    for file_base, spec in FILE_SPECS.items():\n","        process_one(file_base, spec)\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":8027874,"sourceId":12702412,"sourceType":"datasetVersion"},{"datasetId":8063703,"sourceId":12755641,"sourceType":"datasetVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":4}
